{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discussion 3\n",
    "==========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t\n",
    "## As more systems and sectors are driven by predictive analytics, there is increasing awareness of the possibility and pitfalls of algorithmic discrimination. In what ways do you think Recommender Systems reinforce human bias? Reflecting on the techniques we have covered, do you think recommender systems reinforce or help to prevent unethical targeting or customer segmentation?  Please provide one or more examples to support your arguments.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommender system can reinforce human bias in some aspect, sometimes people can be creating model algorithms with some purpose of reach/ target some constrains goals in order to bring profit to the organization/ company etc., if is not closely observe this can definitely be skewed to some kind of discriminations or bias. Even when the recommender system can be used with precaution and a standard unbiased system, we can see that attacker of recommender system can be also a problem which definitely can reinforce the attacker bias into the recommender system making an unethical recommender system.\n",
    "\n",
    "#### We have use item-item and user-user contribute filtering so far on this course and I will say most of the companies use item-item for their algorithms model for recommender system. One the most challenge it’s to know how well those algorithms can judge items predictions just base on an item being clicked on a website or for example when people buy books and maybe after their bought those books, they didn’t enjoy it that much reading it but now the recommender system can be bias and start matching similar books to those people their but that now maybe they don’t want to even read similar books. Just the previews example of buying books can be very bad also on bias for grouping algorithms which can be falsely putting items together without maybe taking into the consideration of the user perceptive onto the equation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The popularity of item can make a matrix be bias because we will have more data points representation of those popular item than the others less popular items and the probabilities can be very high for popular items and this algorithm will be giving less opportunity for selection to less popular item. \n",
    "#### We can also see decision bias relative with popularity because the most that x variable is taking in consideration because of their popularity the more this variable will be appearing on the top items for decision making.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One of the example we can see was the COMPAS in the criminal justice system which was implemented to predict a score risk number that provide guidance to judge to see if a person will be a high risk to re-offending. Later on they didn’t want to continue to use this algorithm because the company didn’t want to shows how this system work and how’s its calculate this score risk. ProPublica study finds that the recommender system was racism bias.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://labs.sogeti.com/algorithms-and-bias-in-the-criminal-justice-system/\n",
    "https://spectrum.ieee.org/computing/software/deconstructing-recommender-systems\n",
    "https://www.researchgate.net/publication/276512301_Decision_Biases_in_Recommender_Systems\n",
    "https://arxiv.org/abs/1901.07555\n",
    "https://www.youtube.com/watch?v=MqoRzNhrTnQ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
