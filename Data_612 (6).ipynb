{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5 : Implementing a Recommender System on Spark\n",
    "#### date: 2019-07-09\n",
    "### by: Sang Yoon (Andy) Hwang, Santosh Cheruku, Anthony Munoz, N.Hwang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import accuracy\n",
    "from surprise import KNNBaseline\n",
    "import surprise\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset set was on CSV file and later we download the dataset and uploaded it onto Databricks database environments system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to find down where is the dataset file location on Databricks \n",
    "import os\n",
    "for dicrectory in os.listdir('/dbfs/FileStore/tables'):\n",
    "  print(dicrectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset & set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this Project, we will be using a previews project recommender system in order to compare the result later on using Spark (pySpark).\n",
    "The Dataset used for this project is MovieLens, which contains a collection of movies with its user rating.\n",
    "we will split the work into two sections. the first section will be using python dataframes and the second section will be using SPark (pySpark) dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Python Dataframe section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# upload the data from database file system and put it to dataframe \n",
    "movie_df = pd.read_csv(\"/dbfs/FileStore/tables/movies.csv\", header='infer')\n",
    "rating_df = pd.read_csv(\"/dbfs/FileStore/tables/ratings.csv\", header='infer', nrows=1000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;\n",
       "RangeIndex: 1000000 entries, 0 to 999999\n",
       "Data columns (total 4 columns):\n",
       "userId       1000000 non-null int64\n",
       "movieId      1000000 non-null int64\n",
       "rating       1000000 non-null float64\n",
       "timestamp    1000000 non-null int64\n",
       "dtypes: float64(1), int64(3)\n",
       "memory usage: 30.5 MB\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checkign the information on the rating dataframe\n",
    "rating_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">&lt;class &apos;pandas.core.frame.DataFrame&apos;&gt;\n",
       "RangeIndex: 27278 entries, 0 to 27277\n",
       "Data columns (total 3 columns):\n",
       "movieId    27278 non-null int64\n",
       "title      27278 non-null object\n",
       "genres     27278 non-null object\n",
       "dtypes: int64(1), object(2)\n",
       "memory usage: 639.4+ KB\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checkign the information on the movies dataframe\n",
    "rating_df.info()\n",
    "movie_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#splitting the data 80/20\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "dat_new = Dataset.load_from_df(rating_df[['userId', 'movieId', 'rating']], reader=reader)\n",
    "trainset, testset = train_test_split(dat_new, test_size=.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Trainig - Alternative least square (ALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this recommender system, we will be using collaborative filtering and because we can use on both python and Spark we select using the alternative least square (ALS) algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Estimating biases using als...\n",
       "RMSE: 0.8625\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ALS\n",
    "bsl_options = {'method': 'als'}\n",
    "algo = surprise.BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "predictions_als = accuracy.rmse(algo.fit(trainset).test(testset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spark section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reading the data to spark dataframe\n",
    "movie_sdf = spark.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/movies.csv')\n",
    "rating_sdf = spark.read.format('csv').options(header='true', inferSchema='true' ).load('/FileStore/tables/ratings.csv' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">root\n",
       "-- userId: integer (nullable = true)\n",
       "-- movieId: integer (nullable = true)\n",
       "-- rating: double (nullable = true)\n",
       "-- timestamp: integer (nullable = true)\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#taking a look how are the Spark dataframe schema\n",
    "rating_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sdf = rating_sdf.select(['userId', 'movieId', 'rating'])\n",
    "train, test = Sdf.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating count summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n",
       "<span class=\"ansigreen\">&lt;command-535492245222866&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n",
       "<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>dispplay<span class=\"ansiyellow\">(</span>rating_sdf<span class=\"ansiyellow\">.</span>select<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">[</span><span class=\"ansiblue\">&apos;rating&apos;</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n",
       "\n",
       "<span class=\"ansired\">NameError</span>: name &apos;dispplay&apos; is not defined</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(rating_sdf.select(['rating']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Trainig - Alternative least square (ALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#creaating the ALS model predictions\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol='userId', itemCol='movieId', ratingCol='rating')\n",
    "\n",
    "predictions = als.fit(train).transform(test).na.drop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------+-----------------+------------------+-----------------+------------------+\n",
       "summary|           userId|           movieId|           rating|        prediction|\n",
       "+-------+-----------------+------------------+-----------------+------------------+\n",
       "  count|          3996727|           3996727|          3996727|           3996727|\n",
       "   mean|69026.86870481772| 9008.085115395672|3.525253413605683|3.4174060526111374|\n",
       " stddev| 40042.4260676503|19725.568379616067|1.051964442325952|0.7229671551406042|\n",
       "    min|                1|                 1|              0.5|         -6.751219|\n",
       "    max|           138493|            131013|              5.0|          9.817508|\n",
       "+-------+-----------------+------------------+-----------------+------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#showing the model predictions summary\n",
    "predictions.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">41</span><span class=\"ansired\">]: </span>0.8150576238969827\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse = evaluator.evaluate(predictions)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Python ALS rmse: 0.8625308707114622 pySpark ALS rmse:0.8150576238969827\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Python ALS rmse: \" + str(predictions_als) , \"pySpark ALS rmse:\" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first problems to find down was the amount for rows that we can work with when using python dataframe against ALS algorithm training data,\n",
    " on this dataset we have about 2M rows and when we try to run the recommender system again he whole dataset the compile crash maybe due to the bid amount of data and all the calculations. so for a quick solution, we reduce the amount of data to a point on where the program could run and that was about 1m rows.\n",
    " \n",
    " On the Spark side, we noticed that it's really good when it comes to working with a big dataset. The training algorithm worked well with the whole dataset without crashing when doing the calculations.\n",
    " \n",
    " The python dataset which was about 1M rows this complete the training model in about 12.84 seconds which was very fast and give an RMSE accuracy of 0.8625. on the otherside with Spark, we use the whole dataset 2M and it did calculate the model in about 1.10 minutes with an RMSE accuracy of 0.8150.\n",
    " \n",
    " if we look at the RMSE we can see that Spark give better result even that it takes a little bit more time which can be debating due that have to work with the whole dataset which was twice the sizes of the python dataframe algorithm model analysis.\n",
    "\n",
    "  we can see the advantages of Spark comes when we need to work with Big dataset because it can work very fast and with good accuracy when applying machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source/References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://surprise.readthedocs.io/en/v1.0.0/_modules/surprise/dataset.html\n",
    " 2. https://surprise.readthedocs.io/en/v1.0.0/dataset.html\n",
    " 3. http://www.3leafnodes.com/apache-spark-introduction-recommender-system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "name": "Data_612",
  "notebookId": 3521822058736568
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
