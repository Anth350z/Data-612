{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this discussion item, please watch the following talk and summarize what you found to be the most important or interesting points. The first half will cover some of the mathematical techniques covered in this unit's reading and the second half some of the data management challenges in an industrial-scale recommendation system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the video, we can see that Spotify it's using collaborative filtering for their recommender system. Spotify uses Alternating Least Squares(ALS) which is one the most popular recommender system to work with a big Scala dataset for which its need for this  company that has about 40 mm user and about 20 mm songs. Even the company uses Hadoop for its big data management, they also implementing Spark. There is a big difference between Hadoop and Spark and it’s how they handle the memory and cache management; Spark its really good working a low-level system with cache and memory storing for a super-fast result while Hadoop also it’s a fast system they use to split the data on disk and keep constantly writing and reading data which can take a lot of time in specific for a company such as Spotify that is managing so much data.\n",
    "\n",
    " \n",
    "\n",
    "With Spark, it’s all about working with scaling big data to optimize performance. One of the many functions is the RDD function which offers a key value pairs for letting you split the data into blocks by assigned pairs of key: value ids and which those blocks can be running all parallel and  let you query the data by the ids and get result in a very time efficiently.\n",
    "\n",
    " \n",
    "\n",
    "Another mentioned topics its Kryo  framework which is very useful for optimizing serialization  and it’s good to use with Spark which can help in the distribution and serialization of the data on RDD function.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
