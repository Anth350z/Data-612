{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please complete the research discussion assignment in a Jupyter or R Markdown notebook. You should post the GitHub link to your research in a new discussion thread.\n",
    "\n",
    "Mitigating the Harm of Recommender Systems\n",
    "\n",
    "Read one or more of the articles below and consider how to counter the radicalizing effects of recommender systems or ways to prevent algorithmic discrimination.\n",
    "\n",
    "1. Renee Diresta, Wired.com (2018): Up Next: A Better Recommendation System\n",
    "\n",
    "2. Zeynep Tufekci, The New York Times (2018): YouTube, the Great Radicalizer\n",
    "\n",
    "3. Sanjay Krishnan, Jay Patel, Michael J. Franklin, Ken Goldberg (n/a): Social Influence Bias in Recommender Systems: A Methodology for Learning, Analyzing, and Mitigating Bias in Ratings\n",
    "\n",
    "#### Please make your post before our meetup on Thursday, and respond to at least one other student's posts by our meetup on Tuesday.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renee Diresta, Wired.com (2018): Up Next: A Better Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading these articles we can notice several important points. we first start on seeing that recommender system engine may work badly because they tend to be very radicalized on their algorithms. we saw an example from where clicking on the web may the recommender system keep in the track on every click item but also can be very bias with just one click to unrelated topics. \n",
    "\n",
    "Sometimes the solution with these recommender systems can be improved with better filtering and double checking the algorithm prediction. the problems come when the solution goes a little bit too much to the point of becoming censorship application which can also be another problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working with AI algorithms will have their benefits of make computer predictions faster out a big dataset with very little people interactions but also I agree with the author about ethical values. They should be team employees that ensure the testing these projects to keep it without bias."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
